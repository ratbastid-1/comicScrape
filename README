comicScrape.php is a command line tool to progressively download a list of comic book titles from GetComics.info. It works entirely on CLI without a browser.

It can be run periodically to keep active titles up to date with latest releases, and has the ability to back-fill series that have several issues already out.

To use this script with a clean conscience, immediately go here and give generously: https://getcomics.info/support/


## GET STARTED OVERVIEW

1) Clone down the repo
2) Use Composer to install dependencies
3) Fill in scrapeConfig.json.SAMPLE
4) Rename scrapeConfig.json.SAMPLE to scrapeConfig.json
5) Edit titles.txt with the names of comics you want to follow
6) Run ./comicScrape.php


## INSTALLATION

comicScrape's requirements are managed by Composer. Get composer at https://getcomposer.org/.

Clone down the repository, change to its directory and run 'composer install'.

Complete the configuration steps below, and run on the command line.


## CONFIGURATION

The scrapeConfig.json file contains the values necessary to configure comicScraper.php for your environment.

The installation comes with a sample called scrapeConfig.json.SAMPLE. You should populate it with values appropriate to your system, and rename it to "scrapeConfig.json".


The shipping contents of scrapeConfig.json.SAMPLE are:

{
	"siteUrl": "https://getcomics.info",
	"queryFormat": "?s=",
	"comicDirectory": "/Path/To/Comics"
	"titlesFile": "./titles.txt",
	"maxPageDepth": 3,
	"onlyFirstPageForExistingSeries": true
}


The fields are:

• siteUrl - the base path to getcomics.info, just in case that ever changes.

• queryFormat - The structure of how to spell a query on GetComics, just incase ditto.

• comicsDirectory - The path on your local machine to where your comics folders live. Must be writeable by the user running this script.

• titlesFile - The name of the file that contains your pull list series titles.

• maxPageDepth - How deep into GetComics' search results to go when downloading a series from the beginning.

• onlyFirstPageForExistingSeries - For comics we already have issues of, only look on the first page of search results for new issues, rather than going "maxPageDepth" deep. This speeds up execution because the latest issue will likely be on the first page.


## PULL LIST

The pull list file (named "titles.txt" by default, but renameable in scrapeconfig.json) should contain a list of the titles you want the script to keep up with.

List these one comic per line, as per the format in the example file.

No other prep is necessary; the script will attempt to set up a folder to save these issues in if it doesn't exist, and the first run will look $maxPageDepth pages deep for the first issue. To start following a new series, just put it's name in the file and run the script.

Some special cases:

1) Sometimes you have to figure out what works on GetComic's search, versus how the market is spelling a series. A popular series named "Batman/Catwoman" is appearing in GetComics as "Batman - Catwoman", so that's what to put in your pull list file. 

2) Sometimes (usually due to special characters) the search term you have to use doesn't match the title as it appears in the downloaded comics. You can configure comicScrape to handle that with this special format:

	Search Term|File Title

An example of that in the sample titles file is "Once and Future|Once & Future". If you configure both values in your file, comicScrape will use "Once and Future" to search GetComics for issues, but handle the fact that the files that come down are named "Once & Future 001 (2020).cbz", for instance. Unless the script is configured to understand this, it'll be unable to track and file these comics properly.

3) GetComics sometimes has an em-dash, or some other hyphen-looking non-hyphen thing in the name of a series. If you copy and paste the series name, you should change this to a normal hyphen in your pull list file because it messes up search URL generation.



## RUNNING THE SCRIPT

Run the script from the command line:

# ./comicScrape.php

When you launch the script, it will:

- Pick up and parse your config file
- Check your command line arguments
- Get the list of comics from the command line or your pull list
- For each title in that list:
	- Find the folder named for them in your "comicsDirectory". Create the series directory if it doesn't exist.
	- Look through that folder for the latest issue it contains. (By highest issue number.)
	- Search GetComics for the title, and get the first "maxPageDepth" pages
	- As each page lands, search it for the issue we're looking for. If we find it, stop pulling search pages and start downloading issues.
	- As issues download, store them in the series folder
	- Parse the filename out of the response headers. If this fails, assemble a reasonable guess at a filename.

It will report on its progress in a cheerful manner, and at the end will dump the list of files it has just added to your directories.


## COMMAND LINE SWITCHES

Four command-line switches enable extra super powers, and can be used in combination:

-t or --title <title>
Allows you to override the pull list file with one or more titles submitted on the command line:
	# ./comicScrape.php -t "Walking Dead" -t "Saga"

-a 
Used in conjuniction with a title expressed in a -t switch, this switch will cause comicScrape to add this title to the end of the pull list. It does not check if this title already exists in the file

-g <string>
Greps the pull list for the given string, returns a list of matches

-s or --silent
Suppresses all command line output

-m or --mail <email>
Supply an email address to send the post-run summary to (handy for cron jobs). Requires functioning mail transport on your machine.

-v or --verbose turns on some debug/process output

-c or --config <filename>
Allows you to specify an alternate config file on the command line. This allows you to keep multiple sets of comics directories, each with separate pull list files.

-h or --help
Get help text.


##USAGE EXAMPLES

Stick this in your crontab to auto-run this at noon and midnight, and email yourself results:

    1 */12 * * * ~/Documents/comicScrape/comicScrape.php -sm you@there.com
    



## TODOS

 • More robust special character handling. I haven't explored what happens if a series title has an illegal character in it (e.g. "Hack/Slash"). It appears that GetComics is solving that for themselves by replacing the / with a -, but nonetheless, this is a place the script is going to be brittle.

 • Add an optional delay factor to our hits to GetComics. Anti-hammering at least, perhaps with a humanizing jitter in the delay.

 • Error handling. If you're going to use this, I hope you can diagnose any issues from PHP's native error messages.

 • Some sort of solution for series that have "runs" that reset the issue number and are indistinguishable aside from their year. I haven't even begun to contemplate how to say I want the Deadpool series that started with issue #1 in 2013 vs the one that started with issue #1 in 2019.


## DISCLAIMERS

This script screen-scrapes a web resource that funds itself with advertising. Current case law seems to indicate that this is not illegal, but it is still somewhat uncool. Any gratitude you have toward me for this script, please express it with a contribution to GetComics.info to help keep their service up, okay?

Go here and give generously: https://getcomics.info/support/

Screen scraping is inherently brittle. While GetComics hasn't changed their page layout in quite some time, there's no reason to think they couldn't do so tomorrow and totally break this script. 
